# agent.py

import re
import openai
from duckduckgo_search import DDGS
import config
from graphManager import CodeGraphManager


class CodeRagAgent:
    def __init__(self, graph_manager: CodeGraphManager):
        self.graph_manager = graph_manager
        openai.api_key = config.OPENAI_API_KEY
        self.tools = {
            "web_search": self._web_search,
            "graph_reason": self._graph_reason
        }
        print("\n--- T√°c t·ª≠ CodeRAG ƒë√£ s·∫µn s√†ng ---")

    def _web_search(self, query: str) -> str:
        print(f"üîé ƒêang th·ª±c hi·ªán Web Search: '{query}'")
        with DDGS() as ddgs:
            results = [r['body'] for r in ddgs.text(query, max_results=3)]
        return "\n".join(results) if results else "Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ n√†o."

    def _graph_reason(self, node_id: str) -> str:
        print(f"üï∏Ô∏è ƒêang truy v·∫•n ƒë·ªì th·ªã t·ª´ n√∫t: '{node_id}'")
        query = """
            MATCH (n:CodeChunk {id: $node_id})-[r]-(neighbor)
            RETURN type(r) as relation, neighbor.content as content, neighbor.id as id
            LIMIT 5
        """
        results = self.graph_manager.run_query(query, node_id=node_id)
        if not results: return f"Kh√¥ng t√¨m th·∫•y n√∫t ho·∫∑c kh√¥ng c√≥ h√†ng x√≥m cho '{node_id}'."

        info = [f"// Quan h·ªá '{res['relation']}' v·ªõi '{res['id']}'\n{res['content']}" for res in results]
        return "\n\n".join(info)

    def run(self, user_prompt, initial_context):
        context = initial_context
        history = []
        for i in range(3):
            print(f"\n--- B∆∞·ªõc suy lu·∫≠n {i + 1}/3 ---")
            prompt = self._build_prompt(user_prompt, context, history)

            response = openai.chat.completions.create(
                model=config.LLM_MODEL,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
            )
            llm_output = response.choices[0].message.content

            thought, action = self._parse_llm_output(llm_output)
            print(f"ü§î Suy nghƒ©: {thought}")
            print(f"‚ö° H√†nh ƒë·ªông: {action}")
            history.append(f"Thought: {thought}\nAction: {action}")

            if "FINISH" in action.upper():
                print("\n‚úÖ T√°c t·ª≠ ƒë√£ quy·∫øt ƒë·ªãnh ho√†n th√†nh.")
                return self.extract_code_from_action(action)

            try:
                tool_name, tool_input = self._parse_action(action)
                if tool_name in self.tools:
                    observation = self.tools[tool_name](tool_input)
                    print(f"üî¨ K·∫øt qu·∫£ quan s√°t: {observation[:200]}...")
                    context += f"\n\n/* --- K·∫øt qu·∫£ t·ª´ c√¥ng c·ª• {tool_name} --- */\n{observation}"
                    history.append(f"Observation: {observation}")
                else:
                    history.append(f"Observation: L·ªói - c√¥ng c·ª• '{tool_name}' kh√¥ng t·ªìn t·∫°i.")
            except Exception as e:
                history.append(f"Observation: L·ªói khi th·ª±c thi h√†nh ƒë·ªông - {e}")

        print("\n‚ö†Ô∏è ƒê√£ ƒë·∫°t ƒë·∫øn gi·ªõi h·∫°n. ƒêang c·ªë g·∫Øng sinh code cu·ªëi c√πng...")
        final_prompt = f"D·ª±a tr√™n to√†n b·ªô ng·ªØ c·∫£nh sau ƒë√¢y, h√£y vi·∫øt code ho√†n ch·ªânh cho y√™u c·∫ßu: '{user_prompt}'\n\n{context}"
        response = openai.chat.completions.create(model=config.LLM_MODEL,
                                                  messages=[{"role": "user", "content": final_prompt}])
        return self.extract_code_from_action(response.choices[0].message.content)

    def _build_prompt(self, user_prompt, context, history):
        return f"""B·∫°n l√† m·ªôt AI l·∫≠p tr√¨nh vi√™n chuy√™n nghi·ªáp. Nhi·ªám v·ª• c·ªßa b·∫°n l√† vi·∫øt code cho y√™u c·∫ßu sau: '{user_prompt}'.

B·∫°n c√≥ c√°c c√¥ng c·ª• sau:
- `web_search(query: str)`: T√¨m ki·∫øm th√¥ng tin tr√™n internet.
- `graph_reason(node_id: str)`: Kh√°m ph√° kho code b·∫±ng c√°ch truy v·∫•n c√°c ƒëo·∫°n code li√™n quan ƒë·∫øn m·ªôt `node_id` ƒë√£ bi·∫øt.

D·ª±a v√†o ng·ªØ c·∫£nh v√† l·ªãch s·ª≠, h√£y suy nghƒ© v√† quy·∫øt ƒë·ªãnh h√†nh ƒë·ªông ti·∫øp theo theo ƒë·ªãnh d·∫°ng:

Thought: [Suy nghƒ© c·ªßa b·∫°n.]
Action: [H√†nh ƒë·ªông b·∫°n s·∫Ω th·ª±c hi·ªán. VD: `web_search("c√¢u h·ªèi")`, `graph_reason("id_c·ªßa_n√∫t")`, ho·∫∑c `FINISH` k√®m theo kh·ªëi code.]

### Ng·ªØ c·∫£nh hi·ªán t·∫°i:
{context}

### L·ªãch s·ª≠:
{''.join(history)}
"""

    def _parse_llm_output(self, text: str):
        thought = re.search(r"Thought:\s*(.*)", text, re.DOTALL).group(1).strip() if re.search(r"Thought:",
                                                                                               text) else "Kh√¥ng c√≥ suy nghƒ©."
        action = re.search(r"Action:\s*(.*)", text, re.DOTALL).group(1).strip() if re.search(r"Action:",
                                                                                             text) else "FINISH"
        return thought, action

    def _parse_action(self, action_text: str):
        match = re.match(r'(\w+)\("([^"]*)"\)', action_text)
        if match: return match.groups()
        raise ValueError("ƒê·ªãnh d·∫°ng h√†nh ƒë·ªông kh√¥ng h·ª£p l·ªá.")

    def extract_code_from_action(self, text: str):
        code_match = re.search(r"```(?:\w+)?\n(.*?)\n```", text, re.DOTALL)
        return code_match.group(1).strip() if code_match else text